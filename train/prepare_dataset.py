import pandas as pd
from pymongo import MongoClient
from sklearn.model_selection import train_test_split
from config import Config
import logging
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DatasetPreparer:
    def __init__(self):
        try:
            self.mongo_client = MongoClient(Config.get_mongo_url())
            self.db = self.mongo_client[Config.MONGO_DB]
            logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB —É—Å–ø–µ—à–Ω–æ: {Config.MONGO_DB}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MongoDB: {e}")
            self.db = None

    def clean_text(self, text):
        if not isinstance(text, str):
            return ""

        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'[^–∞-—è–ê-–Ø—ë–Åa-zA-Z0-9\s.,!?-]', '', text)

        return text.strip()

    def load_labeled_data(self):
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

        if self.db is None:
            logger.warning("MongoDB –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
            return pd.DataFrame(columns=['text', 'label'])

        try:
            cursor = self.db.labeled_posts.find({}, {'text': 1, 'sentiment': 1})

            data = []
            for doc in cursor:
                text = self.clean_text(doc.get('text', ''))
                sentiment = doc.get('sentiment', 'neutral')

                if text and sentiment in ['negative', 'neutral', 'positive']:
                    data.append({
                        'text': text,
                        'label': sentiment
                    })

            df = pd.DataFrame(data)
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")

            return df
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return pd.DataFrame(columns=['text', 'label'])

    def create_synthetic_dataset(self):
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞")

        positive_examples = [
            "–û—Ç–ª–∏—á–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç! –û—á–µ–Ω—å –¥–æ–≤–æ–ª–µ–Ω –ø–æ–∫—É–ø–∫–æ–π",
            "–ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –≤—Å–µ–º",
            "–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å, –±—ã—Å—Ç—Ä–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞",
            "–õ—É—á—à–µ–µ, —á—Ç–æ —è –ø–æ–∫—É–ø–∞–ª –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è",
            "–ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç, –±—É–¥—É –∑–∞–∫–∞–∑—ã–≤–∞—Ç—å –µ—â—ë",
            "–í–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ! –ü—Ä–µ–≤–∑–æ—à–ª–æ –≤—Å–µ –æ–∂–∏–¥–∞–Ω–∏—è",
            "–°—É–ø–µ—Ä –∫–∞—á–µ—Å—Ç–≤–æ, —Ü–µ–Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ä–∞–≤–¥–∞–Ω–∞",
            "–û—á–µ–Ω—å —Ä–∞–¥ –ø–æ–∫—É–ø–∫–µ, –≤—Å—ë –Ω–∞ –≤—ã—Å—à–µ–º —É—Ä–æ–≤–Ω–µ",
            "–ü—Ä–µ–∫—Ä–∞—Å–Ω—ã–π —Ç–æ–≤–∞—Ä, —Å–æ–≤–µ—Ç—É—é –≤—Å–µ–º –¥—Ä—É–∑—å—è–º",
            "–ü–æ—Ç—Ä—è—Å–∞—é—â–µ! –ò–º–µ–Ω–Ω–æ —Ç–æ, —á—Ç–æ –Ω—É–∂–Ω–æ",
        ] * 150

        negative_examples = [
            "–£–∂–∞—Å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é",
            "–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω –ø–æ–∫—É–ø–∫–æ–π, –∑—Ä—è –ø–æ—Ç—Ä–∞—Ç–∏–ª –¥–µ–Ω—å–≥–∏",
            "–ü–ª–æ—Ö–æ–π —Å–µ—Ä–≤–∏—Å, –¥–æ–ª–≥–∞—è –¥–æ—Å—Ç–∞–≤–∫–∞",
            "–ù–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—é",
            "–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≤–∞–ª, –Ω–∏–∫–æ–º—É –Ω–µ —Å–æ–≤–µ—Ç—É—é",
            "–û—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω—ã–π —Ç–æ–≤–∞—Ä, –¥–µ–Ω—å–≥–∏ –Ω–∞ –≤–µ—Ç–µ—Ä",
            "–£–∂–∞—Å–Ω–æ —Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω, –≤–µ—Ä–Ω—É –æ–±—Ä–∞—Ç–Ω–æ",
            "–ö–æ—à–º–∞—Ä–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–µ —Å—Ç–æ–∏—Ç —Å–≤–æ–∏—Ö –¥–µ–Ω–µ–≥",
            "–•—É–¥—à–∞—è –ø–æ–∫—É–ø–∫–∞ –≤ –º–æ–µ–π –∂–∏–∑–Ω–∏",
            "–ö–∞—Ç–µ–≥–æ—Ä–∏—á–µ—Å–∫–∏ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é —ç—Ç–æ –±–∞—Ä–∞—Ö–ª–æ",
        ] * 150

        neutral_examples = [
            "–û–±—ã—á–Ω—ã–π —Ç–æ–≤–∞—Ä, –Ω–∏—á–µ–≥–æ –æ—Å–æ–±–µ–Ω–Ω–æ–≥–æ",
            "–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∑–∞ —Å–≤–æ—é —Ü–µ–Ω—É",
            "–°—Ä–µ–¥–Ω–µ–Ω—å–∫–æ, –º–æ–∂–Ω–æ –±—ã–ª–æ –∏ –ª—É—á—à–µ",
            "–ü—Ä–∏–µ–º–ª–µ–º–æ, –Ω–æ –µ—Å—Ç—å –Ω—é–∞–Ω—Å—ã",
            "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç",
            "–ù–∞ —Ç—Ä–æ–µ—á–∫—É, –Ω–µ –±–æ–ª–µ–µ",
            "–°–æ–π–¥—ë—Ç, –Ω–æ –æ–∂–∏–¥–∞–ª –±–æ–ª—å—à–µ–≥–æ",
            "–ù–∏—á–µ–≥–æ –≤—ã–¥–∞—é—â–µ–≥–æ—Å—è, –æ–±—ã—á–Ω–∞—è –≤–µ—â—å",
            "–ö–∞—á–µ—Å—Ç–≤–æ —Å—Ä–µ–¥–Ω–µ–µ, —Ü–µ–Ω–∞ –∞–¥–µ–∫–≤–∞—Ç–Ω–∞—è",
            "–í —Ü–µ–ª–æ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–æ –µ—Å—Ç—å –Ω–µ–¥–æ—á—ë—Ç—ã",
        ] * 150

        data = []

        for text in positive_examples:
            data.append({'text': self.clean_text(text), 'label': 'positive'})

        for text in negative_examples:
            data.append({'text': self.clean_text(text), 'label': 'negative'})

        for text in neutral_examples:
            data.append({'text': self.clean_text(text), 'label': 'neutral'})

        df = pd.DataFrame(data)
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)

        logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(df)} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
        logger.info(f"–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö: {len([x for x in data if x['label'] == 'positive'])}")
        logger.info(f"–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö: {len([x for x in data if x['label'] == 'negative'])}")
        logger.info(f"–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö: {len([x for x in data if x['label'] == 'neutral'])}")

        return df

    def prepare_dataset(self):
        logger.info("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")

        df = self.load_labeled_data()

        if len(df) < 100:
            logger.warning(f"–ú–∞–ª–æ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö ({len(df)}), –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö...")
            synthetic_df = self.create_synthetic_dataset()
            df = pd.concat([df, synthetic_df], ignore_index=True)
        else:
            logger.info(f"–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(df)}")

        initial_len = len(df)
        df = df.drop_duplicates(subset=['text'])
        logger.info(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {initial_len - len(df)}")

        df = df[df['text'].str.len() > 5]
        logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤: –æ—Å—Ç–∞–ª–æ—Å—å {len(df)}")

        label_map = {'negative': 0, 'neutral': 1, 'positive': 2}
        df['label'] = df['label'].map(label_map)

        label_counts = df['label'].value_counts().sort_index()
        logger.info("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:")
        for label, count in label_counts.items():
            label_name = ['negative', 'neutral', 'positive'][label]
            logger.info(f"   {label_name}: {count} ({count/len(df)*100:.1f}%)")

        train_df, temp_df = train_test_split(
            df,
            test_size=0.3,
            random_state=42,
            stratify=df['label']
        )
        val_df, test_df = train_test_split(
            temp_df,
            test_size=0.5,
            random_state=42,
            stratify=temp_df['label']
        )

        logger.info(f"\n–î–∞—Ç–∞—Å–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:")
        logger.info(f"   üìö Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)")
        logger.info(f"   üéØ Val: {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)")
        logger.info(f"   üß™ Test: {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)")

        return train_df, val_df, test_df

    def __del__(self):
        if hasattr(self, 'mongo_client') and self.mongo_client:
            self.mongo_client.close()